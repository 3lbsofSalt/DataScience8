{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_df = pd.read_csv('data/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_df['Label'].unique()\n",
    "particle_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 inputs, 6 outputs\n",
    "model1 = MLPClassifier(hidden_layer_sizes=[20, 30, 40], max_iter=500)\n",
    "model2 = MLPClassifier(hidden_layer_sizes=[30, 50, 30], max_iter=500)\n",
    "model3 = MLPClassifier(hidden_layer_sizes=[30, 50, 30, 50], max_iter=500)\n",
    "model4 = MLPClassifier(hidden_layer_sizes=[50, 30, 50, 30], max_iter=500)\n",
    "model5 = MLPClassifier(hidden_layer_sizes=[50, 40, 40], max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10, 2):\n",
    "    df = particle_df.sample(frac=i*.02)\n",
    "    X = df.drop(axis=1, columns=['Label'])\n",
    "    y=df['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.2)\n",
    "    results4 = cross_validate(model4, X_train, y_train, scoring='f1_macro')\n",
    "    display(i*.02, results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = particle_df.sample(frac=.5)\n",
    "X = df.drop(axis=1, columns=['Label'])\n",
    "y=df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = cross_validate(model1, X_train, y_train, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "results2 = cross_validate(model2, X_train, y_train, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "results3 = cross_validate(model3, X_train, y_train, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "results4 = cross_validate(model4, X_train, y_train, scoring='f1_macro', cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = cross_validate(model5, X_train, y_train, scoring='f1_macro')\n",
    "results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results1, results2, results3, results4, results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may need to install networkx with pip\n",
    "model5 = MLPClassifier(hidden_layer_sizes=[50, 40, 40], max_iter=500)\n",
    "\n",
    "import networkx as nx\n",
    "import colorsys\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def show_ann(mlp):\n",
    "    hidden_layers_n = len(mlp.coefs_)-1\n",
    "    layers_n = hidden_layers_n + 2\n",
    "    input_neurons_n = len(mlp.coefs_[0])\n",
    "    hidden_neurons_n = [len(mlp.coefs_[i+1]) for i in range(hidden_layers_n)]\n",
    "    output_neurons_n = len(mlp.coefs_[-1][0])\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    pos = {}\n",
    "\n",
    "    # Create the neurons of the input layer\n",
    "    for i in range(input_neurons_n):\n",
    "        pos['Layer0_{}'.format(i)] = (i,layers_n-1)\n",
    "\n",
    "    for j in range(hidden_layers_n):\n",
    "        # Create the neurons of the j'th hidden layer\n",
    "        prev_layer = j\n",
    "        cur_layer = j+1\n",
    "        if (j == 0):\n",
    "            prev_size = input_neurons_n\n",
    "        else:\n",
    "            prev_size = hidden_neurons_n[j-1]\n",
    "        for i in range(hidden_neurons_n[j]):\n",
    "            pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "            for k in range(prev_size):\n",
    "                w = mlp.coefs_[prev_layer][k][i]\n",
    "                G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    # Create the neurons of the output layer\n",
    "    prev_layer = hidden_layers_n\n",
    "    cur_layer = hidden_layers_n+1\n",
    "    for i in range(output_neurons_n):\n",
    "        pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "        for k in range(hidden_neurons_n[-1]):\n",
    "            w = mlp.coefs_[prev_layer][k][i]\n",
    "            G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    edges = G.edges()\n",
    "    colors = [colorsys.hsv_to_rgb(0 if G[u][v]['weight'] < 0 else 0.65,\n",
    "                                  1,#min(1, abs(G[u][v]['weight'])),\n",
    "                                  1) for u,v in edges]\n",
    "    weights = [abs(G[u][v]['weight'])*2 for u,v in edges]\n",
    "    plt.figure(figsize=(15, 18))\n",
    "    nx.draw(G, pos, node_color='y', node_size=450, width=weights, edge_color=colors)\n",
    "    \n",
    "show_ann(model1.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ann(model3.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ann(model5.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model5.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0:10]\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred, labels=['Electron', 'Ghost', 'Pion', 'Muon', 'Kaon', 'Proton'])\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Electron', 'Ghost', 'Pion', 'Muon', 'Kaon', 'Proton']).plot()\n",
    "precision_recall_fscore_support(y_test, pred, labels=['Electron', 'Ghost', 'Pion', 'Muon', 'Kaon', 'Proton'])\n",
    "f1_score(y_test, pred, average='macro')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
